{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e413197a",
   "metadata": {},
   "source": [
    "## Data and SNR Plots\n",
    "This notebook was used to create Figures 1 and 4, which show examples of tetromino data across all scenarios for both classes, and an example across four signal-to-noise ratios respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d6799",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'your_env_name' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n your_env_name ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import random\n",
    "import pickle as pkl\n",
    "\n",
    "from math import floor\n",
    "import torch\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "np.random.seed(2023)\n",
    "random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783aca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ./data/tetris_utils.py functions\n",
    "\n",
    "def normalise_data(patterns, backgrounds):\n",
    "    patterns /= np.linalg.norm(patterns, ord='fro')\n",
    "    d_norm = np.linalg.norm(backgrounds, ord='fro')\n",
    "    distractor_term = backgrounds if 0 == d_norm else backgrounds / d_norm\n",
    "    return patterns, distractor_term\n",
    "\n",
    "def scale_to_bound(row, bound):\n",
    "    scale = bound / np.max(np.abs(row))\n",
    "    return row * scale\n",
    "\n",
    "def generate_background():\n",
    "    sample = np.random.normal(0, 1, size=[64,64])\n",
    "    return sample\n",
    "\n",
    "def get_patterns(params):\n",
    "    manip = params['manipulation']\n",
    "    scale = params['pattern_scale']\n",
    "    t = np.array([\n",
    "            [manip,0],\n",
    "            [manip,manip],\n",
    "            [manip,0]\n",
    "        ])\n",
    "    \n",
    "    l = np.array([\n",
    "            [manip,0],\n",
    "            [manip,0],\n",
    "            [manip,manip]\n",
    "        ])\n",
    "    \n",
    "    pattern_dict = {\n",
    "        't': np.kron(t, np.ones((scale,scale))),\n",
    "        'l': np.kron(l, np.ones((scale,scale))),\n",
    "    }\n",
    "\n",
    "    chosen_patterns = []\n",
    "    for pattern_name in params['patterns']:\n",
    "        chosen_patterns.append(pattern_dict[pattern_name])\n",
    "    return chosen_patterns\n",
    "\n",
    "positions = [[8,8],[32,40]]\n",
    "\n",
    "def generate_linear_pattern(cls=0):\n",
    "    if cls == 0:\n",
    "        params = {\"patterns\": [\"t\"]}\n",
    "    else:\n",
    "        params = {\"patterns\": [\"l\"]}\n",
    "    params['manipulation_type'] = 'additive'\n",
    "    params['manipulation'] = 1.0\n",
    "    params['pattern_scale'] = 8\n",
    "    chosen_pattern = get_patterns(params)\n",
    "    \n",
    "    pos = positions[cls]\n",
    "\n",
    "    pattern = np.zeros((64,64))\n",
    "    pattern[pos[0]:pos[0]+chosen_pattern[0].shape[0], pos[1]:pos[1]+chosen_pattern[0].shape[1]] = chosen_pattern[0]\n",
    "    \n",
    "    return gaussian_filter(pattern, 1.5)\n",
    "\n",
    "def generate_multiplicative_pattern(cls=0, snr=0.2):\n",
    "    if cls == 0:\n",
    "        params = {\"patterns\": [\"t\"]}\n",
    "    else:\n",
    "        params = {\"patterns\": [\"l\"]}\n",
    "\n",
    "    params['manipulation_type'] = 'additive'\n",
    "    params['pattern_scale'] = 8\n",
    "    params['manipulation'] = 1.0\n",
    "\n",
    "    chosen_pattern = get_patterns(params)\n",
    "    \n",
    "    pos = positions[cls]\n",
    "    pattern = np.zeros((64,64))\n",
    "    pattern[pos[0]:pos[0]+chosen_pattern[0].shape[0], pos[1]:pos[1]+chosen_pattern[0].shape[1]] = chosen_pattern[0]\n",
    "    \n",
    "    return gaussian_filter(pattern, 1.5)\n",
    "\n",
    "def generate_translations_rotations_pattern(cls=0):\n",
    "    if cls == 0:\n",
    "        params = {\"patterns\": [\"t\"]}\n",
    "    else:\n",
    "        params = {\"patterns\": [\"l\"]}\n",
    "    params['manipulation_type'] = 'additive'\n",
    "    params['manipulation'] = 1.0\n",
    "    params['pattern_scale'] = 4\n",
    "    pattern = get_patterns(params)[0]\n",
    "    pattern_adj = pattern\n",
    "    rand = np.random.randint(0, high=4)\n",
    "    if rand == 1:\n",
    "        pattern_adj = np.rot90(pattern)\n",
    "    elif rand == 2:\n",
    "        pattern_adj = np.rot90(np.rot90(pattern))\n",
    "    elif rand == 3:\n",
    "        pattern_adj = np.rot90(np.rot90(np.rot90(pattern)))\n",
    "    \n",
    "    rand_y = np.random.randint(0, high= 64-pattern_adj.shape[0])\n",
    "    rand_x = np.random.randint(0, high= 64-pattern_adj.shape[1])\n",
    "    pos = (rand_y, rand_x)\n",
    "\n",
    "    pattern = np.zeros((64,64))\n",
    "    pattern[pos[0]:pos[0]+pattern_adj.shape[0], pos[1]:pos[1]+pattern_adj.shape[1]] = pattern_adj\n",
    "    \n",
    "    return gaussian_filter(pattern, 1.5)\n",
    "\n",
    "def generate_xor_pattern(cls=0):\n",
    "    params = {\"patterns\": [\"t\",\"l\"]}\n",
    "    params['manipulation_type'] = 'additive'\n",
    "    params['manipulation'] = 1.0\n",
    "    params['pattern_scale'] = 8\n",
    "    chosen_patterns  = get_patterns(params)\n",
    "    adj_signs = [-1, 1]\n",
    "    poses = positions\n",
    "\n",
    "    pattern = np.zeros((64,64))\n",
    "\n",
    "    if cls == 0:\n",
    "        rand_sign = random.sample(adj_signs, 1)\n",
    "        pattern[poses[0][0]:poses[0][0]+chosen_patterns[0].shape[0], poses[0][1]:poses[0][1]+chosen_patterns[0].shape[1]] = chosen_patterns[0] * rand_sign\n",
    "        pattern[poses[1][0]:poses[1][0]+chosen_patterns[1].shape[0], poses[1][1]:poses[1][1]+chosen_patterns[1].shape[1]] = chosen_patterns[1] * rand_sign\n",
    "    else:\n",
    "        rand_signs = random.sample(adj_signs, 2)\n",
    "        pattern[poses[0][0]:poses[0][0]+chosen_patterns[0].shape[0], poses[0][1]:poses[0][1]+chosen_patterns[0].shape[1]] = chosen_patterns[0] * rand_signs[0]\n",
    "        pattern[poses[1][0]:poses[1][0]+chosen_patterns[1].shape[0], poses[1][1]:poses[1][1]+chosen_patterns[1].shape[1]] = chosen_patterns[1] * rand_signs[1]\n",
    "    \n",
    "    return gaussian_filter(pattern, 1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_imagenet(sample_size: int) -> np.array:\n",
    "    image_paths = glob(f'../imagenet_images/*')\n",
    "    backgrounds = np.zeros((sample_size, 64*64))\n",
    "    new_width, new_height = 64,64\n",
    "    i = 0\n",
    "    for image_path in random.sample(image_paths, sample_size+100):\n",
    "        if i == sample_size:\n",
    "            return backgrounds\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        width, height = img.size   # Get dimensions\n",
    "        if width < 64 or height < 64:\n",
    "            continue\n",
    "\n",
    "        if height <= width:\n",
    "            scale_factor=64/height\n",
    "        else:\n",
    "            scale_factor = 64/width\n",
    "                                                    \n",
    "        resize = (int(scale_factor*width),int(scale_factor*height))\n",
    "\n",
    "        img = img.resize(resize)\n",
    "        width, height = img.size\n",
    "\n",
    "        left = round((width - new_width)/2)\n",
    "        top = round((height - new_height)/2)\n",
    "        x_right = round(width - new_width) - left\n",
    "        x_bottom = round(height - new_height) - top\n",
    "        right = width - x_right\n",
    "        bottom = height - x_bottom\n",
    "\n",
    "        # Crop the center of the image\n",
    "        img = img.crop((left, top, right, bottom))\n",
    "\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        grey = np.dot(np.array(img)[...,:3], [0.299, 0.587, 0.114]).reshape((64*64))\n",
    "        #print(grey.shape)\n",
    "        #print(backgrounds.shape)\n",
    "        #print(backgrounds[i].shape)\n",
    "        backgrounds[i] = grey - grey.mean()\n",
    "        i+=1\n",
    "    return backgrounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca5d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 2 examples from each (scenario, background) pair, 1 of each class\n",
    "snrs = [0.5, 0.4, 0.5, 0.825, 0.825, 0.825, 0.5, 0.2, 0.5, 0.6, 0.2, 0.6]\n",
    "# snrs = [0.4] * 8\n",
    "def generate_n_examples(n=2, snrs=snrs):\n",
    "    backgrounds = [generate_background(), generate_background()]\n",
    "    smoothed_backgrounds = [gaussian_filter(backgrounds[0].copy(), 10), gaussian_filter(backgrounds[1].copy(), 10)]\n",
    "    imagenet_backgrounds = [generate_imagenet(1), generate_imagenet(1)]\n",
    "    \n",
    "    linear_0, linear_1 = generate_linear_pattern(0), generate_linear_pattern(1)\n",
    "    mult_0, mult_1 = generate_multiplicative_pattern(0, snr=0.725), generate_multiplicative_pattern(1, snr=0.725)\n",
    "    tr_0, tr_1 = generate_translations_rotations_pattern(0), generate_translations_rotations_pattern(1)\n",
    "    xor_0, xor_1 = generate_xor_pattern(0), generate_xor_pattern(1)\n",
    "    \n",
    "    patterns = {\n",
    "        'Linear': [linear_0, linear_1],\n",
    "        'Multiplicative': [mult_0, mult_1],\n",
    "        'Translations_Rotations': [tr_0, tr_1],\n",
    "        'XOR': [xor_0, xor_1]\n",
    "    }\n",
    "    \n",
    "    backgrounds_dict = {\n",
    "        'Correlated': smoothed_backgrounds,\n",
    "        'Uncorrelated': backgrounds,\n",
    "        'ImageNet': imagenet_backgrounds\n",
    "    }\n",
    "    \n",
    "    keys = ['Linear Uncorrelated', 'Linear Correlated', 'Linear ImageNet', 'Multiplicative Uncorrelated', 'Multiplicative Correlated',\n",
    "            'Multiplicative ImageNet', 'Translations_Rotations Uncorrelated', 'Translations_Rotations Correlated',\n",
    "            'Translations_Rotations ImageNet', 'XOR Uncorrelated', 'XOR Correlated', 'XOR ImageNet']\n",
    "    data_dict = {}\n",
    "\n",
    "    output_array = []\n",
    "    for snr_ind, key in enumerate(keys):\n",
    "        data = np.zeros((n,4096))\n",
    "        data_dict[key] = list()\n",
    "        scenario, background_type = key.split(' ')\n",
    "        bg = backgrounds_dict[background_type]\n",
    "        ind = 0\n",
    "        for j in range(2):\n",
    "            for i in range(2):\n",
    "                if 'XOR' in key and i == 1:\n",
    "                    scalar = -1\n",
    "                else:\n",
    "                    scalar = 1\n",
    "                pat = patterns[scenario][j] * scalar\n",
    "                back = bg[i]\n",
    "                if 'Multiplicative' in key:\n",
    "                    pat_copy = 1 - snrs[snr_ind] * pat.copy()\n",
    "                else:\n",
    "                    pat_copy = pat.copy()\n",
    "                \n",
    "                normalised_patterns, normalised_backgrounds = normalise_data(np.reshape(pat_copy,(64,64)), np.reshape(back, (64,64)))\n",
    "                if 'Multiplicative' in key:\n",
    "                    data[ind] = np.reshape( normalised_patterns * normalised_backgrounds, (4096))\n",
    "                else:\n",
    "                    data[ind] = np.reshape(snrs[snr_ind] * normalised_patterns + (1 - snrs[snr_ind]) * normalised_backgrounds, (4096))\n",
    "                data[ind] = scale_to_bound(data[ind], 1)\n",
    "                output_array.append(data[ind])\n",
    "                ind += 1\n",
    "        data_dict[key] += [data]\n",
    "                \n",
    "            \n",
    "    output_dict = {}\n",
    "    for key, value in data_dict.items():\n",
    "        output_dict[key] = np.vstack(value)\n",
    "    return output_dict, output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c276cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict, data_array = generate_n_examples(n=4)\n",
    "print(data_dict.keys())\n",
    "print(data_array.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 2\n",
    "cols = 12\n",
    "\n",
    "fig = plt.figure(figsize=(12,4), constrained_layout=True)\n",
    "# grid for pairs of subplots\n",
    "grid = plt.GridSpec(rows, cols, hspace=0.15, wspace=0.1)\n",
    "\n",
    "j = 0\n",
    "keys = ['LIN WHITE', 'LIN CORR', 'LIN IMAGENET', 'MULT WHITE', 'MULT CORR',\n",
    "        'MULT IMAGENET', 'RIGID WHITE', 'RIGID CORR', 'RIGID IMAGENET','XOR WHITE', 'XOR CORR', 'XOR IMAGENET']\n",
    "\n",
    "for i in range(cols):\n",
    "    # create fake subplot just to title pair of subplots\n",
    "\n",
    "    gs = gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=grid[i], wspace=0.1)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    ax.imshow(np.reshape(data_array[j], (64,64)), cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
    "    ax.set_title(keys[i].replace(' ', '\\n').replace('_', '\\n'), fontdict = {'fontsize' : 10})\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[1], sharey=ax)\n",
    "    ax2.imshow(np.reshape(data_array[j+1], (64,64)), cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
    "    \n",
    "    for axs in [ax, ax2]:\n",
    "        axs.tick_params(left=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "    \n",
    "    gs = gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=grid[i+12], wspace=0.1)\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0])\n",
    "    ax3.imshow(np.reshape(data_array[j+2], (64,64)), cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[1], sharey=ax3)\n",
    "    im = ax4.imshow(np.reshape(data_array[j+3], (64,64)), cmap=\"RdBu_r\", vmin=-1, vmax=1)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_ylabel(f'Y=0\\n', fontsize=12, y=0.7)\n",
    "        ax.yaxis.set_label_coords(0.3,-0.10)\n",
    "        ax3.set_ylabel(f'Y=1\\n', fontsize=12, y=0.7)\n",
    "        ax3.yaxis.set_label_coords(0.3, -0.10)\n",
    "        \n",
    "    \n",
    "    j+=4\n",
    "#     j+=2\n",
    "    # hide ticks and labels\n",
    "    for axs in [ax3, ax4]:\n",
    "        axs.tick_params(left=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.2)  \n",
    "    \n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.82, 0.115, 0.02, 0.76])\n",
    "fig.colorbar(im, cax=cbar_ax, ticks=[-1.0,0,1.0])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "out_folder_path = f'./figures/'\n",
    "Path(f'{out_folder_path}').mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig('./figures/data_plot_corrected_2.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_snrs(data, rows=4, cols=12, y_test='placeholder', labels='placeholder', figsize=(12,4)):\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=figsize, constrained_layout=True)\n",
    "    keys = ['LIN WHITE', 'LIN CORR', 'LIN IMAGENET', 'MULT WHITE', 'MULT CORR',\n",
    "            'MULT IMAGENET', 'RIGID WHITE', 'RIGID CORR', 'RIGID IMAGENET','XOR WHITE', 'XOR CORR', 'XOR IMAGENET']\n",
    "    \n",
    "    for j, scenario in enumerate(list(data.keys())):\n",
    "        axs[0,j].set_title(keys[j].replace(' ', '\\n'), fontdict = {'fontsize' : 10})\n",
    "        for i in range(rows):\n",
    "            axs[i,0].set_ylabel(str(chosen_snrs[i]), fontdict = {'fontsize' : 11})\n",
    "            axs[i,0].yaxis.set_label_coords(0,0.5)\n",
    "            axs[i,j].imshow(np.reshape(data[scenario][i],(64,64)), cmap=\"RdBu_r\", vmin=-1, vmax=1)   \n",
    "            axs[i,j].set_xticks([])\n",
    "            axs[i,j].set_yticks([])\n",
    "    fig.suptitle('$\\\\alpha$', fontweight='semibold', size=20, x=0.1, y=0.52, rotation=90)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.82, 0.115, 0.02, 0.76])\n",
    "    fig.colorbar(im, cax=cbar_ax, ticks=[-1.0,0,1.0])\n",
    "    out_folder_path = f'./figures/'\n",
    "    Path(f'{out_folder_path}').mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig('./figures/snr_plot.png', bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = generate_background()\n",
    "smoothed_background = gaussian_filter(background.copy(), 10)\n",
    "imagenet_background = generate_imagenet(1)\n",
    "\n",
    "linear = generate_linear_pattern(1)\n",
    "multiplicative = generate_multiplicative_pattern(1)\n",
    "tr = generate_translations_rotations_pattern(1)\n",
    "xor = generate_xor_pattern(1)\n",
    "\n",
    "backgrounds = [background,smoothed_background, imagenet_background]\n",
    "keys = ['LIN WHITE', 'LIN CORR', 'LIN IMAGENET', 'MULT WHITE', 'MULT CORR',\n",
    "            'MULT IMAGENET', 'RIGID WHITE', 'RIGID CORR', 'RIGID IMAGENET','XOR WHITE', 'XOR CORR', 'XOR IMAGENET']\n",
    "patterns = {\n",
    "    'LIN': linear,\n",
    "    'MULT': multiplicative,\n",
    "    'RIGID': tr,\n",
    "    'XOR': xor\n",
    "}\n",
    "\n",
    "chosen_snrs = [0.05, 0.3, 0.55, 0.8]\n",
    "data_dict = {}\n",
    "for i, key in enumerate(keys):\n",
    "    data_dict[keys[i]] = np.zeros((4,4096))\n",
    "    data = np.zeros((4,4096))\n",
    "    scenario, background_type = key.split(' ')\n",
    "    for j, snr in enumerate(chosen_snrs):\n",
    "\n",
    "        pat = patterns[scenario]\n",
    "        \n",
    "        if background_type == 'CORR':\n",
    "            back = backgrounds[1]\n",
    "        elif background_type == 'IMAGENET':\n",
    "            back = backgrounds[2]\n",
    "        else:\n",
    "            back = backgrounds[0]\n",
    "   \n",
    "        if 'MULT' in key:\n",
    "            pat_copy = 1 - snr * pat.copy()\n",
    "        else:\n",
    "            pat_copy = pat.copy()\n",
    "\n",
    "        normalised_patterns, normalised_backgrounds = normalise_data(np.reshape(pat_copy,(64,64)), np.reshape(back, (64,64)))\n",
    "        if 'MULT' in key:\n",
    "            data[j] = np.reshape( normalised_patterns * normalised_backgrounds, (4096))\n",
    "        else:\n",
    "            data[j] = np.reshape(snr * normalised_patterns + (1 - snr) * normalised_backgrounds, (4096))\n",
    "  \n",
    "        data[j] = scale_to_bound(data[j], 1)\n",
    "    data_dict[key] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786818a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_snrs(data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-tris-nKUk6Slr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
